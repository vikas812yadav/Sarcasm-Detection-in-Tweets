# -*- coding: utf-8 -*-
"""Sarcasm Detection in Tweets.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-nY534sQbsKGmY4rMhgT7avoUN3WIogA
"""

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline

from fastai.text import *

from google.colab import drive
drive.mount('/content/drive')

cd 'drive/My Drive/Finding Chandler'

import pandas as pd

df1 = pd.read_csv('train.csv')

df1.shape

df.head()

df2 = pd.read_csv('test.csv')

df_com = pd.concat([df1, df2], ignore_index=True)
df_com.head()

df_com.drop(['label'], axis=1,inplace=True)
df_com.head()

df_com.to_csv('data_lang.csv', index=False)

data_lm = TextLMDataBunch.from_csv(Path(''), 'data_lang.csv')
data_lm.save('data_lm1.pkl')

data_lm = load_data('','data_lm1.pkl', bs=48)

data_lm = (TextList.from_folder('Finding Chandler', extensions={'.csv'})
            .split_by_rand_pct(0.1)
            .label_for_lm()           
            .databunch(bs=48))
data_lm.save('data_lm1.pkl')

data_lm = load_data('','data_lm.pkl', bs=48)

data_lm.show_batch(10)

config = awd_lstm_lm_config.copy()
config['qrnn'] = True

gc.collect()
torch.cuda.empty_cache()

learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.65)

learn.lr_find()
learn.recorder.plot(skip_end=15)

learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))

learn.save('fit_head2')

learn.load('fit_head2')

learn.unfreeze()

learn.fit_one_cycle(6, 1e-3, moms=(0.8,0.7))

learn.save('fine_tuned3')

learn.load('fine_tuned3');

TEXT = "I enjoy"
N_WORDS = 40
N_SENTENCES = 3

print("\n".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))

learn.save_encoder('fine_tuned_enc3')

df = pd.read_csv('train.csv')
df.name = df.replace(to_replace='#sarcasm', value="",regex=True, inplace=True)

df.to_csv('mod_train.csv', index=False)
#df.head()

data_clas = TextDataBunch.from_csv('', 'mod_train.csv', text_cols=2, label_cols=1, vocab=data_lm.vocab)
data_clas.save('data_clas1.pkl')

data_clas = load_data('','data_clas1.pkl')

len(data_clas.train_ds)

learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.7)
learn.load_encoder('fine_tuned_enc2')
#learn.clip_grad(0.3)

learn.load('fifth3_final_93%')

learn.export('final_model')

learn.lr_find()

learn.recorder.plot()

learn.fit_one_cycle(1, 1e-3, moms=(0.8,0.7))

learn.save('first2')

learn.load('first2')

learn.freeze_to(-2)
learn.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))



learn.predict("Can't wait to see more of your breast feeding selfies.")

learn.save('second3')
learn.load('second3')

learn.freeze_to(-3)
learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))

learn.save('third2')
learn.load('third2')

learn.unfreeze()
learn.fit_one_cycle(4, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))

learn.save('final5')
learn.load('final5')

learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))

#learn.save('clip5')
learn.load('clip5')

learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))

learn.save('sixth5')
learn.load('sixth5')

learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))

learn.save('ninth5')
learn.load('ninth5')

learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))

test_df = pd.read_csv('test.csv')

learn.export()

test_df.head()

import numpy as np
label = np.zeros((1975, 1))

test_df['text']

for i in range(1975):
  cl,l,p = learn.predict(test_df['text'][i])
  label[i] = int(l)

cl,l,p = learn.predict("Can't wait to see more of your breast feeding selfies.")

int(l)

np.savetxt("submission13.csv", label)

preds,y,losses = learn.get_preds(with_loss=True)
interp = ClassificationInterpretation(learn, preds, y, losses)

interp.plot_confusion_matrix()

interp.most_confused()

y

learn.predict(data_clas.valid_ds[10][0])



#learn.unfreeze()
learn.fit_one_cycle(8, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))



#learn.unfreeze()
learn.fit_one_cycle(8, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))

learn.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))

learn.load('fourth_final')

learn.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))

learn.save('fifth')
learn.load('fifth')

learn.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))

learn.save('sixth')
learn.load('sixth')

learn.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))

#learn.save('seventh')
learn.load('seventh')

learn.load('seventh')

