{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm Detection in Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HT1zUsep2Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjbRtcgWu0aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCoZ7_GCqAyn",
        "colab_type": "code",
        "outputId": "4c72fe04-582e-49e6-c75c-2641d70ee07d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZDHocqIqB_U",
        "colab_type": "code",
        "outputId": "0db47d0f-d9e7-431c-dc43-328d7df8027e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd 'drive/My Drive/Finding Chandler'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Finding Chandler\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95S1qcAPqmFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMKqEhOHv4oC",
        "colab_type": "code",
        "outputId": "f04c9628-46a9-4ab9-9c92-325ff9e86a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39780, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N52WJ6_Jqy3b",
        "colab_type": "code",
        "outputId": "262f6723-d8cc-4cbf-8271-c8547f094d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>@Estrada21Karla Happy Happy Birthday Mommy Kar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Thank you Sabrina, great talk on timeless conn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Really not looking forward to tomorrow. I'm no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Miley and Liam's relationship in the last song...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>What doesn't kill you makes you stronger. \" Wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  label                                               text\n",
              "0   0      0  @Estrada21Karla Happy Happy Birthday Mommy Kar...\n",
              "1   1      0  Thank you Sabrina, great talk on timeless conn...\n",
              "2   2      0  Really not looking forward to tomorrow. I'm no...\n",
              "3   3      1  Miley and Liam's relationship in the last song...\n",
              "4   4      1  What doesn't kill you makes you stronger. \" Wh..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy4u_9CwrM_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZbgiNnCsQOz",
        "colab_type": "code",
        "outputId": "cad85571-0a6c-4ff8-8adb-af73a0ee2be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "df_com = pd.concat([df1, df2], ignore_index=True)\n",
        "df_com.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@Estrada21Karla Happy Happy Birthday Mommy Kar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Thank you Sabrina, great talk on timeless conn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Really not looking forward to tomorrow. I'm no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Miley and Liam's relationship in the last song...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>What doesn't kill you makes you stronger. \" Wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  label                                               text\n",
              "0   0    0.0  @Estrada21Karla Happy Happy Birthday Mommy Kar...\n",
              "1   1    0.0  Thank you Sabrina, great talk on timeless conn...\n",
              "2   2    0.0  Really not looking forward to tomorrow. I'm no...\n",
              "3   3    1.0  Miley and Liam's relationship in the last song...\n",
              "4   4    1.0  What doesn't kill you makes you stronger. \" Wh..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOdseo2PlPVO",
        "colab_type": "code",
        "outputId": "1b86b779-8ad2-484f-baff-46f1a4ac00c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_com.drop(['label'], axis=1,inplace=True)\n",
        "df_com.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@Estrada21Karla Happy Happy Birthday Mommy Kar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Thank you Sabrina, great talk on timeless conn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Really not looking forward to tomorrow. I'm no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Miley and Liam's relationship in the last song...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>What doesn't kill you makes you stronger. \" Wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id                                               text\n",
              "0   0  @Estrada21Karla Happy Happy Birthday Mommy Kar...\n",
              "1   1  Thank you Sabrina, great talk on timeless conn...\n",
              "2   2  Really not looking forward to tomorrow. I'm no...\n",
              "3   3  Miley and Liam's relationship in the last song...\n",
              "4   4  What doesn't kill you makes you stronger. \" Wh..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdaxmtTElWkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_com.to_csv('data_lang.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "02d220a6-75b8-4051-efba-1655fd60eab1",
        "id": "VZQl9-7nNlQq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "data_lm = TextLMDataBunch.from_csv(Path(''), 'data_lang.csv')\n",
        "data_lm.save('data_lm1.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9H2HnV7R6gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data('','data_lm1.pkl', bs=48)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQLOh8CDWUCy",
        "colab_type": "code",
        "outputId": "7587c8d7-7e5b-4860-c21d-66a8771c924d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "data_lm = (TextList.from_folder('Finding Chandler', extensions={'.csv'})\n",
        "            .split_by_rand_pct(0.1)\n",
        "            .label_for_lm()           \n",
        "            .databunch(bs=48))\n",
        "data_lm.save('data_lm1.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PknShxicaS_i",
        "colab": {}
      },
      "source": [
        "data_lm = load_data('','data_lm.pkl', bs=48)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgooQTrQanlY",
        "colab_type": "code",
        "outputId": "6fe6aeac-1ba1-4e2f-e693-656264168e7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        }
      },
      "source": [
        "data_lm.show_batch(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>that you got to speak . xxmaj we got , xxunk to me , do n't speak to me ' so we never knew which . xxmaj same result xxbos xxmaj it 's not so much blowing my diet as preventing the xxunk from developing freezer burn . # sarcasm xxbos xxmaj why would you pay $ 80 for a bra at xxmaj victoria 's xxmaj secret when i will</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>'s not being talked about # sarcasm xxbos xxmaj this week long hotel stay might not be so bad xxbos xxmaj you know its cold outside when you go outside and its cold # sarcasm xxbos wow i feel loved ... # not # sarcasm xxbos xxmaj the best feeling in the world is when someone you hate tells a joke and nobody laughs # sarcasm xxbos xxmaj who would</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>❤ ️ # not # sarcasm xxbos xxmaj y'all swear everything is a relationship goal . xxmaj stfu xxbos xxmaj when love and trust are gone i guess this is moving on xxmaj everyone i do right does me wrong xxmaj so every lonely night , i sing this song xxbos xxmaj taste w ur eye , ears , lips &amp; touch 2 know deep satisfaction &amp; understanding . xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>my headphones and just listen all day people talking around maybe one day i will just wake up and speak german # yeahright # sarcasm xxbos xxunk xxmaj really hoping it 's on youtube soon because it 's xxunk here ( # xxmaj rebel ) and i have school in the morning so i could nt watch it xxbos xxmaj we had an amazing day in xxmaj xxunk on the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>xxmaj mr. t xxmaj xxunk ! xxbos xxmaj we all want our parents to be proud of our accomplishments xxbos xxunk papa johns pizza is the best tho lmao i love it xxbos xxmaj every year , i realize how stupid i was the year before . # sarcasm xxbos xxmaj life is like a bowel movement , it 's still gon na happen whether your sh*t 's together or</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>or book bc i also have a physics exam yay for xxunk . # sarcasm xxbos xxmaj empire xxmaj state of xxmaj xxunk xxunk xxmaj shout out to for bringing xxbos xxmaj do n't feel good at all ! i love having the feeling i 'm going to throw up very 5 minutes . # not xxbos xxup xxunk and rain does n't make good weather for work or cycling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>nice and i love talking to people . xxmaj but lately i rather be left alone . # sarcasm xxbos i am so heartbroken , shattered and xxunk xxup beyond xxup words ... i lost my grandma last night ... xxmaj it hurts xxbos xxmaj so , go away 4 a week &amp; come back 2 find xxmaj xxunk has gone to spuds , xxup xxunk on way to xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>happy because i 'm not searching for xxunk in other people anymore . i 'm happy because i am getting better everyday . xxbos xxmaj no more foolin around . xxmaj time to get serious xxbos xxmaj just heard a conversation going on at xxmaj xxunk -mart about a girl who is getting married to a hobo ... # xxmaj umm # hownice ? xxbos xxmaj that awkward moment when</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>to veterans xxmaj mrs. xxmaj clinton ? i 'm not trying to be xxunk , you know as well as i do we do not trust you . xxbos xxmaj and we as in xxup xxunk and i have most of you females mad 😭 😂 ☺ ️ that 's okay tho . birds need love too . # xxup not # sarcasm xxbos and there are too - bright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>is how removing tattoos with xxunk works xxbos xxmaj this bitch really took her time to write a letter cuz of xxmaj cam xxmaj newtown 's dab dance . # whitepeopleproblems xxbos xxmaj the xxmaj whisper xxmaj challenge with the bae back in the day # youtube # game # challengeaccepted # xxunk xxbos i need to write something on paper , remember it xxbos xxunk xxunk xxmaj who the</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3MIoMnryDi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = awd_lstm_lm_config.copy()\n",
        "config['qrnn'] = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIpZWUrL3MJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFLsxmA2R_Xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.65)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQZHKByLVjXW",
        "colab_type": "code",
        "outputId": "a74c9587-7092-47f0-aa91-11350179dfb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot(skip_end=15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4XOWZ/vHvo2qrWLJluRe5F3CX\nAQM2EAj9RwsskIQECHGcQjbZNJLspsAuSZZkE1haDMSELAkJhiT0lgAmgMEybrh3W7Zly3KRLMuq\nz++PGbBQZKvN0Whm7s91ncsz55w587yekW69p7zH3B0REZH2Sop2ASIiEtsUJCIi0iEKEhER6RAF\niYiIdIiCREREOkRBIiIiHaIgERGRDlGQiIhIhyhIRESkQ1KiXUBb9e7d2wsKCqJdhohITFm8ePFe\nd88PYtsxFyQFBQUUFRVFuwwRkZhiZluD2rZ2bYmISIcoSEREpEMUJCIi0iEKEhER6RAFiYiIdIiC\nREREOiTQIDGzXDObb2ZrzGy1mc1osvxMMztoZkvD0w+CrEdERCIv6B7JncAL7j4WmASsbmadN9x9\ncni6NahC9pQf4cdPr6SmriGotxARSUiBBYmZ5QCzgIcA3L3G3Q8E9X4tWbx1P/Pe3MIdL66JVgki\nInEpyB7JMKAUmGdmS8zsQTPLbGa9GWa2zMyeN7MTmtuQmc02syIzKyotLW1XMRdM6M91pwzlgTc2\n88qq3e3ahoiI/LMggyQFmArc5+5TgErglibrvAcMdfdJwP8Cf2luQ+4+190L3b0wP7/9Q8V8/6Jx\nnDCgB994fBk7DlS1ezsiInJUkEFSDBS7+zvh5/MJBcuH3L3c3Q+FHz8HpJpZ76AK6paazD2fnEp9\ng/OV379Hbf2xj5e8uWEvn3xgIZ9/pIiH39zM+t0VuHtQpYmIxKzABm109xIz225mY9x9LXA2sKrx\nOmbWD9jt7m5mJxEKtrKgagIo6J3JTz8xga/8fgl3vLiW71047iPL1+2u4CfPrebVtaUMzO1OUhK8\nHN4Vlp+dzoj8TLLSU8nulkJ2txTG9uvBJZMHkJUec+NfiohERNC//W4GHjWzNGATcIOZzQFw9/uB\nK4EvmlkdUAVc453wZ//FEwewcFMZcxds4onFxfTL6Ub/nG6kJCXx0qoSMtNT+N6FY/nsqQWkpySz\nfd9h3tywl7c2llFy8AjF+w9zqLqO8qpayo9s5T+fXcWlkwdw7UlDmDgoN+jyRUS6FIu13TWFhYUe\niWHkq+vq+d3bW9m0t5KSg0fYdfAI+yqrueDE/vzr2aPomZnW4jbcnaXbD/D7d7bx9PKdHKltYHjv\nTCYOyuHEgTlMGJjD+AE9yO6W2uF628Pd2X+4loy0ZLqlJkelBhHpGsxssbsXBrLtRA2SSCs/Ustf\nl+zg9XV7WbHjALvLqz9c1jsrnWG9Mxial8nw/EzG9e/B+P496JOdjpm1+z1r6hpYuKmMrWWVHDhc\ny8Gq0LSnopodB6rYsb+Kqtp68rPT+cPnT2Fkn6xINFVEYpCCpJGuGiRN7ak4wvs7DrKmpIIteyvZ\nsvcwW8oq2VNxNGDyMtMY0y+bfjndyM9OJz8rnQG53fnY2D7H7EFU19Xz5oa9PLu8hJdXlVB+pO7D\nZRlpyeR0T6V3VjoDc7szsGd3+vXoxq8XbCLJ4LHZpzA8X2EikogUJI3ESpAcS/mRWtbsqmDVzoOs\n3lXBuj0V7CmvprSimprwWWQFeRncdtmJzBx19FTn6rp6Hl24jXte3UBZZQ3Z3VL4+Pi+XDShPxMH\n5ZLTPZW0lOZPwlu3u4Jr5y4kJdn44+wZFPRu7nIeEYlnCpJGYj1IjsXdKa+q471t+7n1mVVs3lvJ\nRRP78/0Lx/H2xjL+5+V17DhQxakj8rhp5jBOH5l/zOBozpqScq6du5Buqcn8cfYMhuRlRKTu3eVH\neHrZTnp0T+WM0fn07dGtxdd88J1rbrdedV09m0orWbe7IjwdYv3uCsoqa/j6OaO54bSCDu0OFElU\nCpJG4jVIGjtSW8/cBZu4+9UN1NY34A4nDuzBd84fy+kje7f7F+mqneV88sGFuMNZY/KZNTqfmaPy\nyc9O/0hPqfRQNVcXDjlm2DQ0OG9u3MujC7fx8urd1Dcc/Q6N7ZfNrNH5FORlkpwESWYkJxn7KmvY\nsOcQ6/ccYsOeQ1RW19E7K50+PdLpk51OSlIS6/dUsKXs8IfbS0kyCnpnMrpvFuVVdfxjw17OHtuH\nO66aRK9WnAwhIkcpSBpJhCD5wNaySh5+awtTh/Tkogn9SUrq+F/ia0squO+1Dbyxfi9llTUA9MlO\n/8ixGzNITUrihtMK+PLHRtIjfNZZaUU18xcX88dF29hSdpieGan8S+FgrjlpCFU19SxYX8qCdaUs\n2rKP2vp//l7lZaYxok8WI/tkkdM9ldKKavZUVLOn/Ag19Q2MzM9iTL9sRvcNTcN6Z37Y63J3Hn5r\nCz95bg09M1P51dVTmDEir8P/HyKJQkHSSCIFSZAaGpxVu8p5fV0pG/YcYmSfLMb378G4/j0wgzte\nXMv8xcXkZabxuZnDWL79IK+s3k1dg3PSsF586uQhnHdCv2ZPCqiqqedAVQ31DU5DAzS406N7akR6\nEe/vOMhX/7CEzWWVnD6yNxdP7M95J/QjN0M9FJHjUZA0oiDpPCuKD3LbM6t4d8s+emWmceW0QVw9\nfTAjonzmV2V1Hb9+fSN/XbaTrWWHSU02Th/Zm8KCXozIz2RknyyG9MrkwOEaVuw4yPLig6zcWU7v\nrDQumTSAk4fnkRyB3p1ILFGQNKIg6VzuzsbSQwzpldmmg/udwd15f0c5zyzfyQsrS9hadvjDZUkG\nHxy6MYPhvTMpOXiEypp6+mSnc9HE/swalc+A3O70z+1GdnpKi8ee6uobSEnuWv8HIq2lIGlEQSLH\nUlldx6bSSjaWHmJT6SFyM9KYMCiH8f17kJmeQlVNPX9fs4enlu3g1TWlH55uDZCZlszAnt0pyMtk\nWH4mw/IyyUxPYW1JBat3lbNqVzm7Dh6hW2oSud3TyM1IDR07stBuwgZ36h0OV9dxuKaeQ9V1VNXU\nk5uRysCe3T+8rqdHt1RSkkInIKQmJzE0L4NThudp5AEJnIKkEQWJREL5kVrW765g54EjlBw8ws6D\nVWzfV8WWskq2lR3+MGSSk4yR+VmMH9CDoXkZHK6pZ39lDQeqaimvqsXs6JlpZkZGajKZ6SlkpSfT\nLS2Z/ZU17DhQRfH+KnYdOPKR8PpAekoSM0bkcdaYPpw5Jp+hebrORyIvyCDRkLWSkHp0S2Xa0F5M\nG/rPy+obnJ0Hqig/UsuI/KyI9RYaGpzahgbq6p26eqemvoGVOw/y2tpSXl9Xyg+fWgmELkg9c0wf\nzhidzynD8+iept6KdG3qkYh0EVv2VvL6ulJeW7uHtzeVcaS2gYy0ZC6a0J8rpw3ipGG9dDGmtJt2\nbTWiIJFEcKS2nnc37+PZ5bt4ZvlOKmvqGdIrg6unD+azpxbo/jfSZgqSRhQkkmgO19TxwvslPF5U\nzNubyuidlc7XPz6KqwsH6ywyaTUFSSMKEklkS7bt5/bnVrNoy35G5Gfy3QvGcc74vtEuS2JAkEGi\nP2dEYsiUIT350xdm8OvrpuEONz1SxM1/WML+8HA3ItGgIBGJMWbGeSf048Wvz+Kb547m+RW7OPdX\nC3h1zZ5olyYJSkEiEqNSk5P4ysdG8Zcvn0avjDRueHgRtzyxnIOHa6NdmiQYBYlIjDtxYA5P3Xwa\nc84YwZ+KtnPGz1/lt29tobaZix9FgqAgEYkD6SnJ3HLBWJ65eSbj+/fgh0+t5Hzt7pJOoiARiSPj\nB/Tg0ZtO5oHPFNLgcMPDi/j16xujXZbEOQWJSJwxMz4+vi8vfm0WF03oz89eWMOCdaXRLkvimIJE\nJE6lpSRxx1UTGd03m5v/sIRtjYbZF4kkBYlIHMtIS+HX100DYPbvijhcUxfliiQeBRokZpZrZvPN\nbI2ZrTazGcdYb7qZ1ZnZlUHWI5KIhuZlcte1U1i7u4LvPLGCWBvNQrq+oHskdwIvuPtYYBKwuukK\nZpYM/Ax4KeBaRBLWGaPz+dZ5Y3h62U7ufU0H3yWyAhtC1MxygFnA9QDuXgM0N47DzcATwPSgahER\n+OIZI1hbUsEdL66lT3Y6VxUOjnZJEieC7JEMA0qBeWa2xMweNLOP3PrNzAYClwP3HW9DZjbbzIrM\nrKi0VGefiLSHmXHHlZOYOao3tzy5QteYSMQEGSQpwFTgPnefAlQCtzRZ51fAd9z9uJfguvtcdy90\n98L8/PxgqhVJAGkpSdz36WmM79+DLz36Hku27Y92SRIHggySYqDY3d8JP59PKFgaKwQeM7MtwJXA\nvWZ2WYA1iSS8rPQU5t0wnT490rnx4UVs2HMo2iVJjAssSNy9BNhuZmPCs84GVjVZZ5i7F7h7AaGg\n+ZK7/yWomkQkpHdWOo/ceBLJScZnHnqH4v26xkTaL+iztm4GHjWz5cBk4HYzm2NmcwJ+XxFpwdC8\nTB658WQOVdfx6QffYU/FkWiXJDFKd0gUSXCLt+7nuofeYXDPDP74hVPIzUiLdkkSAN0hUUQCM21o\nTx74TCGbyyr57G/e5VC1rn6XtlGQiAinjezNvZ+cyvs7y/naY0t19bu0iYJERAA4Z3xfvnP+GF5Z\nvZuXV+2OdjkSQxQkIvKhG04bxui+Wfz46VVU1dRHuxyJEQoSEflQanISt116IjsOVHH3q+ujXY7E\nCAWJiHzEycPzuGLKQOYu2MTGUl2sKC1TkIjIP/nuhePolprMD/+6UgfepUUKEhH5J/nZ6XzrvDH8\nY8Nenl2xK9rlSBenIBGRZn3q5KGcOLAHP/jrSg2hIselIBGRZiUnGXdeM4Xa+gY+/8hi3aZXjklB\nIiLHNCI/i7uuncKaknK++fgyHS+RZilIROS4zhrTh+9eMJbnVpTwv3/fEO1ypAsK7Fa7IhI/Pj9z\nOKt3VfA/L69jdN9szj+xX7RLki5EPRIRaZGZ8ZMrJjBpcC7ffHwZ2/fp4LscpSARkVbplprM3ddO\nAeDb85fT0KDjJRKiIBGRVhvcK4P/uHgcb28q47dvb4l2OdJFKEhEpE3+pXAwHxvbh58+v0ZDqAig\nIBGRNjIzfnrFBLqlJvONPy2jrr4h2iVJlClIRKTN+vToxm2XncjS7Qf49YJN0S5HokxBIiLt8v8m\n9ueiCf351SvrWL+7ItrlSBQpSESkXcyMWy89gcz0FL775AqdxZXAFCQi0m55Wel878JxFG3dz2OL\ntke7HIkSBYmIdMhV0wZxyvBe/OT51eypOBLtciQKFCQi0iFmxu2XT6C6roFbn14V7XIkChQkItJh\nw/Oz+MpZI3lm+S5eXbMn2uVIJws0SMws18zmm9kaM1ttZjOaLL/UzJab2VIzKzKz04OsR0SCM+eM\nEYzsk8W//+V93bskwQTdI7kTeMHdxwKTgNVNlv8NmOTuk4EbgQcDrkdEApKWksRPrpjAjgNV/OqV\n9dEuRzpRYEFiZjnALOAhAHevcfcDjddx90N+9E45mYDOHxSJYdMLenHtSYN56B+bWbnzYLTLkU4S\nZI9kGFAKzDOzJWb2oJllNl3JzC43szXAs4R6Jf/EzGaHd30VlZaWBliyiHTULeePo2dGKt97cgX1\nurYkIQQZJCnAVOA+d58CVAK3NF3J3f8c3vV1GXBbcxty97nuXujuhfn5+QGWLCIdlZORyn9cPJ5l\nxQf53dtbol2OdIIgg6QYKHb3d8LP5xMKlma5+wJguJn1DrAmEekEl0wawMxRvfn5S+vYdbAq2uVI\nwAILEncvAbab2ZjwrLOBj5xkbmYjzczCj6cC6UBZUDWJSOcwM/7zshOprW/gx0/p2pJ4F/RZWzcD\nj5rZcmAycLuZzTGzOeHlnwDeN7OlwD3A1Y0OvotIDBual8m/njOKF1aW6NqSOGex9nu7sLDQi4qK\nol2GiLRCTV0D5/7ydVKTk3j+X2eSkqxroKPFzBa7e2EQ29anKiKBSUtJ4pYLxrJ+zyH+WKRBHeOV\ngkREAnXeCf2YXtCTX768jkPVuuI9HilIRCRQZsb3LxrP3kM13P/axmiXIwFQkIhI4CYPzuWSSQN4\n4I1NOh04DilIRKRTfOu8MTjw8xfXRbsUiTAFiYh0isG9MrjhtAKeXFLM+zs0Dlc8UZCISKf50pkj\nyemeys9eWBPtUiSCFCQi0mlyuqfylbNG8sb6vfxj/d5olyMRoiARkU513YyhDMztzs9eWEODRgeO\nCwoSEelU6SnJfOPc0azYcZBnV+yKdjkSAQoSEel0l04eyNh+2fz8pbXU1DVEuxzpIAWJiHS65CTj\nOxeMZWvZYR5btC3a5UgHKUhEJCrOHJ3PKcN7cdff1mvolBinIBGRqDAzbrlgHHsP1TDvH5ujXY50\ngIJERKJm8uBcPja2D/Pe2kJVTX20y5F2alWQmNkIM0sPPz7TzL5qZrnBliYiiWDOGSPYV1nD44s1\nzHysam2P5Amg3sxGAnOBwcDvA6tKRBLG9IKeTBvak1+/vonaep3BFYtaGyQN7l4HXA78r7t/C+gf\nXFkikijMjDlnjGDHgSqeXa7rSmJRa4Ok1syuBT4LPBOelxpMSSKSaM4e24dRfbK4//WNxNrtv6X1\nQXIDMAP4L3ffbGbDgN8FV5aIJJKkJOMLZ4xgTUkFr60tjXY50katChJ3X+XuX3X3P5hZTyDb3X8W\ncG0ikkAumTSAATnduO913UUx1rT2rK3XzKyHmfUC3gMeMLP/CbY0EUkkaSlJfG7mcN7dvI/FW/dH\nuxxpg9bu2spx93LgCuARdz8ZOCe4skQkEV0zfTC5Ganc99qGaJcibdDaIEkxs/7Av3D0YLuISERl\npqdw/akFvLJ6D2tKyqNdjrRSa4PkVuBFYKO7LzKz4cD64MoSkUR1/akFZKYlc8+rOlYSK1p7sP1x\nd5/o7l8MP9/k7p9o6XVmlmtm881sjZmtNrMZTZZ/ysyWm9kKM3vLzCa1rxkiEi9yM9L49IyhPLt8\nJ5v3Vka7HGmF1h5sH2RmfzazPeHpCTMb1IqX3gm84O5jgUnA6ibLNwNnuPsE4DZCV82LSIK76fTh\npCYn6VhJjGjtrq15wFPAgPD0dHjeMZlZDjALeAjA3Wvc/UDjddz9LXf/4PSMhUBrwklE4lx+djrX\nTB/Mk+/tYMeBqmiXIy1obZDku/s8d68LTw8D+S28ZhhQCswzsyVm9qCZZR5n/c8Bzze3wMxmm1mR\nmRWVlupiJZFEMPuMEQDM1XUlXV5rg6TMzD5tZsnh6dNAWQuvSQGmAve5+xSgEriluRXN7CxCQfKd\n5pa7+1x3L3T3wvz8lvJLROLBwNzuXDF1II8t2k5pRXW0y5HjaG2Q3Ejo1N8SYBdwJXB9C68pBord\n/Z3w8/mEguUjzGwi8CBwqbu3FE4ikkC+eOZIausbeEg3vurSWnvW1lZ3v8Td8929j7tfBhz3rC13\nLwG2m9mY8KyzgVWN1zGzIcCTwHXuvq7t5YtIPBvWO5PzTujHHxdto7pON77qqjpyh8R/a8U6NwOP\nmtlyYDJwu5nNMbM54eU/APKAe81sqZkVdaAeEYlD15w0hP2Ha3ll1Z5olyLHkNKB11pLK7j7UqCw\nyez7Gy2/CbipAzWISJw7fWRvBuZ257FF27hoom6D1BV1pEeimwaISOCSk4yrCgfxjw17Kd5/ONrl\nSDOOGyRmVmFm5c1MFYSuJxERCdxVhYMBeLyoOMqVSHOOGyTunu3uPZqZst29I7vFRERabWBud2aO\nyufxou3UN2hnSFfTkV1bIiKd5urCwew8eIR/bNgb7VKkCQWJiMSEc8b3oVdmGn9ctC3apUgTChIR\niQnpKclcPmUgL6/aTdkhXenelShIRCRmXD19MLX1zp+X7Ih2KdKIgkREYsbovtlMGZLL79/ZpoPu\nXYiCRERiyudOH8amvZW8tLIk2qVImIJERGLKBSf2Z1jvTO55bQPu6pV0BQoSEYkpyUnGF88Ywfs7\nylmwXqcCdwUKEhGJOZdNGUj/nG7c86puxdsVKEhEJOakpSQxe9Zw3t28j0Vb9kW7nISnIBGRmHTN\n9CH0ykzjXvVKok5BIiIxqXtaMp87fRivri1l5c6D0S4noSlIRCRmffqUoWSnp3DvqxujXUpCU5CI\nSMzK6Z7KdTOG8tz7u1i/uyLa5SQsBYmIxLSbZg4nIzWZu/6uYyXRoiARkZjWKzONz55awDPLd7JO\nvZKoUJCISMz7fLhXcuff1ke7lISkIBGRmNczM43rTyvguRW7WFuiXklnU5CISFy46fThZKalcJd6\nJZ1OQSIicaFnZhrXn1rAsyt2saakPNrlJBQFiYjEjZtmDiM7Xb2SzqYgEZG4kZuRxg2nFfDcihL1\nSjpRoEFiZrlmNt/M1pjZajOb0WT5WDN728yqzeybQdYiIonhxtOHkZmWzN26rqTTBN0juRN4wd3H\nApOA1U2W7wO+Cvw84DpEJEHkZoSuK3l2xS427NEZXJ0hsCAxsxxgFvAQgLvXuPuBxuu4+x53XwTU\nBlWHiCSez50+jG4pydyjMbg6RZA9kmFAKTDPzJaY2YNmltmeDZnZbDMrMrOi0tLSyFYpInEnLyud\n62YM5a9Ld7B5b2W0y4l7QQZJCjAVuM/dpwCVwC3t2ZC7z3X3QncvzM/Pj2SNIhKnbpo5jNTkJN1F\nsRMEGSTFQLG7vxN+Pp9QsIiIBK5Pdjc+efIQ/rxkB9v3HY52OXEtsCBx9xJgu5mNCc86G1gV1PuJ\niDT1hVkjSDbj3tfUKwlS0Gdt3Qw8ambLgcnA7WY2x8zmAJhZPzMrBv4N+HczKzazHgHXJCIJol9O\nN66ePpj5i4vZdbAq2uXErUCDxN2Xho9tTHT3y9x9v7vf7+73h5eXuPsgd+/h7rnhx7qKSEQiZvas\n4dQ3OP+3cGu0S4lburJdROLa4F4ZnDOuL79/ZxtHauujXU5cUpCISNy7/rQC9h+u5allO6NdSlxS\nkIhI3JsxPI8xfbN5+M0tuHu0y4k7ChIRiXtmxmdPLWDVrnIWbdkf7XLijoJERBLCZVMGkNM9lYff\n2hztUuKOgkREEkJGWgrXTB/Miyt3s/OATgWOJAWJiCSMT58yFHedChxpChIRSRgfnAr8h3d1KnAk\nKUhEJKHccNow9h+uVa8kghQkIpJQZozI48wx+dz5ynpKK6qjXU5cUJCISML5j4vHU1Vbzx0vrol2\nKXFBQSIiCWdEfhY3nj6MxxcXs7z4QMsvkONSkIhIQrr5YyPJy0znR0+tpKFBV7t3hIJERBJSdrdU\nvn3+GN7bdoC/LN0R7XJimoJERBLWlVMHMWlQDj99fg2HquuiXU7MUpCISMJKSjJ+dMkJ7Kmo5qE3\nNHRKeylIRCShTRnSk3PG9WHeW5upVK+kXRQkIpLwvnTWSA4cruUP726LdikxSUEiIglv6pCezBie\nx9wFm6iu09ApbaUgEREBvnzWSPZUVPPEYp3B1VYKEhER4LSReUwalMP9r2+krr4h2uXEFAWJiAih\nuyh++ayRbNt3mGeW74p2OTFFQSIiEnbOuL6M7pvFva9t0NXubaAgEREJS0oyvnTmSNbtPsRLq3ZH\nu5yYoSAREWnk4on9GZGfyW3PrNLV7q0UaJCYWa6ZzTezNWa22sxmNFluZnaXmW0ws+VmNjXIekRE\nWpKSnMR/XzmRnQer+NnzGma+NYLukdwJvODuY4FJwOomyy8ARoWn2cB9AdcjItKiaUN7ceNpw/jd\nwq0s3FQW7XK6vMCCxMxygFnAQwDuXuPuTQf+vxR4xEMWArlm1j+omkREWuub545haF4G33liOVU1\nukjxeILskQwDSoF5ZrbEzB40s8wm6wwEtjd6Xhye9xFmNtvMisysqLS0NLiKRUTCuqcl89MrJrK1\n7DC/eGlttMvp0oIMkhRgKnCfu08BKoFb2rMhd5/r7oXuXpifnx/JGkVEjmnGiDw+fcoQHnpzM4u3\n7o92OV1WkEFSDBS7+zvh5/MJBUtjO4DBjZ4PCs8TEekSbrlgHANyuvPdJ5dTU6cr3psTWJC4ewmw\n3czGhGedDaxqstpTwGfCZ2+dAhx0d11SKiJdRlZ6CrdeegLrdh/igTc2RbucLinos7ZuBh41s+XA\nZOB2M5tjZnPCy58DNgEbgAeALwVcj4hIm509ri8XTujHXX9bz9ayymiX0+WYe2wNA1BYWOhFRUXR\nLkNEEszu8iOc/YvXmTIkl0duPAkzi3ZJbWJmi929MIht68p2EZFW6NujG98+fwxvrN/LU8t2Rruc\nLkVBIiLSSp86eSiTBudy2zOrOHC4JtrldBkKEhGRVkpOMm6//ET2H67l9ueaDtSRuBQkIiJtcMKA\nHGbPGs6fiop5RSMEAwoSEZE2+9o5oxjbL5tbnlxO2aHqaJcTdQoSEZE2Sk9J5lfXTKa8qo7vPrmC\nWDv7NdIUJCIi7TC2Xw++ed5oXlq1m/mLi6NdTlQpSERE2ulzpw/npGG9+PHTq9i+73C0y4kaBYmI\nSDslJxm/uGoSAN/40zLq6hNzLC4FiYhIBwzulcGtl57Au1v28ctX1kW7nKhQkIiIdNAVUwdxdeFg\n7nl1I6+t3RPtcjqdgkREJAJ+fOkJjO2Xzdf/uJRdB6uiXU6nUpCIiERAt9Rk7vnUVGrqGrj590uo\nTaDjJQoSEZEIGZGfxe1XTKBo637ueDFxbs+bEu0CRETiyaWTB7Joyz7mLthEXb3z/YvGkZwUW0PO\nt5WCREQkwn58yYmkJCXxmzc3s+PAYX519RS6pyW3e3t19Q3c//pGZo7KZ9Lg3AhWGhnatSUiEmHJ\nScaPLjmBH1w8npdW7eaaBxayt51jcm0sPcQn7n+bn7+0jhdXlkS40shQkIiIBOTG04dx36emsbak\nnEvvfpNX17T+1OCGBmfem5u58M432FpWyd2fnMK3zx8bYLXtpyAREQnQ+Sf247HZM0hPSeKGhxdx\nw7x32VR66JjruzsLN5Vx7QML+fHTqzh1RB4vfW0WF08c0IlVt43u2S4i0glq6hr47VtbuPNv66mu\nq+e6UwqYMSKP4fmZDO6ZQZLlpKdfAAAJzUlEQVTB8++X8MAbm1hefJBemWl867wxXDN9cETuDx/k\nPdsVJCIinWhPxRHueGEt898r5oNfv8lJRmZaMuVH6hjWO5ObZg7jE1MH0S21/Qfom1KQNKIgEZF4\ncLCqlk2lh9i8t5LNeyspOXiEj4/vyznj+pIUwOnCQQaJTv8VEYmCnO6pTBnSkylDeka7lA7TwXYR\nEekQBYmIiHRIoLu2zGwLUAHUA3VN98+ZWU/gN8AI4Ahwo7u/H2RNIiISWZ1xjOQsd997jGXfA5a6\n++VmNha4Bzi7E2oSEZEIifaurfHA3wHcfQ1QYGZ9o1uSiIi0RdBB4sBLZrbYzGY3s3wZcAWAmZ0E\nDAUGNV3JzGabWZGZFZWWlgZasIiItE3QQXK6u08FLgC+bGazmiz/KZBrZkuBm4ElhI6nfIS7z3X3\nQncvzM/PD7hkERFpi0CPkbj7jvC/e8zsz8BJwIJGy8uBGwAsNAbAZmBTkDWJiEhkBRYkZpYJJLl7\nRfjxucCtTdbJBQ67ew1wE7AgHC7HtHjx4r1mtrXJ7BzgYAvzjvf8g8eN5/UGjnWSQEuaq6ct67S1\nPS097khbWqq1pXXi6bNpTVuazgvys9H37PjzY/V7dqxlHf1shrZYdXu5eyATMJzQMZBlwErg++H5\nc4A54cczgHXAWuBJoGc732tuS/OO9/yDx03mFXWg7f9UT1vWaWt7WnrckbZ0tD3x9Nm0pi2d+dno\nexaf37Ou+Nm0NAXWI3H3TcCkZubf3+jx28DoCLzd062Yd7znTx9jnUjW05Z12tqe1jzuiI60J54+\nm9a0pem8ID8bfc+OPz9Wv2fHWhbNz+a4Ym7Qxs5iZkUe0ABnnS2e2gLx1R61peuKp/YE3ZZoX0fS\nlc2NdgERFE9tgfhqj9rSdcVTewJti3okIiLSIeqRiIhIh8R9kJjZb8xsj5m1eTBIM5tmZivMbIOZ\n3WWN7ndpZjeb2RozW2lm/x3Zqo9bU8TbY2Y/MrMdZrY0PF0Y+cqbrSeQzya8/Btm5mbWO3IVt1hT\nEJ/NbWa2PPy5vGRmnXLj7oDackf4Z2a5mf05fPp/pwioPVeFf/4bzCzwYykdacMxtvdZM1sfnj7b\naP5xf7aaFeQpYV1hAmYBU4H32/Had4FTAAOeBy4Izz8LeAVIDz/vE+Pt+RHwzXj4bMLLBgMvAluB\n3rHcHqBHo3W+Ctwfw205F0gJP/4Z8LMY/2zGAWOA14DCrtqGcH0FTeb1InTxdy+gZ/hxz+O193hT\n3PdI3H0BsK/xPDMbYWYvhMcAeyM88jBN1ulP6Id4oYf+dx8BLgsv/iLwU3evDr/HnmBbcVRA7YmK\nANvyS+DbhMZ66zRBtMc/eoFuJp3UpoDa8pK714VXXUgz4+oFJaD2rHb3tZ1Rf/j92tWGYzgPeNnd\n97n7fuBl4Pz2/p6I+yA5hrnAze4+DfgmcG8z6wwEihs9Lw7Pg9C1LzPN7B0ze93Mpgdabcs62h6A\nr4R3OfzGQveJiZYOtcXMLgV2uPuyoAttpQ5/Nmb2X2a2HfgU8IMAa21JJL5nH7iR0F+70RTJ9kRL\na9rQnIHA9kbPP2hXu9qbcPdsN7Ms4FTg8Ua7/tLbuJkUQl3CU4DpwJ/MbHg4wTtVhNpzH3Abob92\nbwN+QegHvVN1tC1mlkHoHjfnRr66tovQZ4O7fx/4vpl9F/gK8MOIFdlKkWpLeFvfB+qARyNTXbtq\niFh7ouV4bTCzG4B/Dc8bCTxnZjXAZne/PNK1JFyQEOqFHXD3yY1nmlkysDj89ClCv1wbd70HATvC\nj4uBJ8PB8a6ZNRAayyYaY9x3uD3uvrvR6x4Angmy4OPoaFtGAMOAZeEfrEHAe2Z2kruXBFx7cyLx\nXWvsUeA5ohAkRKgtZnY9cDFwdjT+8Gok0p9NNDTbBgB3nwfMAzCz14Dr3X1Lo1V2AGc2ej6I0LGU\nHbSnvUEfIOoKE1BAowNUwFvAVeHHBkw6xuuaHnS6MDx/DnBr+PFoQl1Ei+H29G+0zteBx2K1LU3W\n2UInHmwP6LMZ1Widm4H5MdyW84FVQH5nfiZBf9fopIPt7W0Dxz7YvpnQgfae4ce9WtPeZuuKxgfa\nyV+ePwC7gFpCPYnPEfqr9QVCA0quAn5wjNcWAu8DG4G7OXoBZxrwf+Fl7wEfi/H2/A5YASwn9FdY\n/1htS5N1ttC5Z20F8dk8EZ6/nNC4SQNjuC0bCP3RtTQ8dcoZaAG25/LwtqqB3cCLXbENNBMk4fk3\nhj+TDcANLbX3eJOubBcRkQ5J1LO2REQkQhQkIiLSIQoSERHpEAWJiIh0iIJEREQ6REEiccHMDnXy\n+z1oZuMjtK16C43u+76ZPd3SqLhmlmtmX4rEe4tEgk7/lbhgZofcPSuC20vxowMMBqpx7Wb2W2Cd\nu//XcdYvAJ5x9xM7oz6RlqhHInHLzPLN7AkzWxSeTgvPP8nM3jazJWb2lpmNCc+/3syeMrO/A38z\nszPN7DUzm2+h+2g8+sG9GcLzC8OPD4UHVlxmZgvNrG94/ojw8xVm9p+t7DW9zdEBKLPM7G9m9l54\nG5eG1/kpMCLci7kjvO63wm1cbmY/juB/o0iLFCQSz+4Efunu04FPAA+G568BZrr7FEKj6d7e6DVT\ngSvd/Yzw8ynA14DxwHDgtGbeJxNY6O6TgAXA5xu9/53uPoGPjqjarPA4T2cTGl0A4AhwubtPJXQP\nnF+Eg+wWYKO7T3b3b5nZucAo4CRgMjDNzGa19H4ikZKIgzZK4jgHGN9oZNQe4RFTc4DfmtkoQiMe\npzZ6zcvu3vieD++6ezGAmS0lNNbRP5q8Tw1HB7pcDHw8/HgGR+/l8Hvg58eos3t42wOB1YTuDQGh\nsY5uD4dCQ3h532Zef254WhJ+nkUoWBYc4/1EIkpBIvEsCTjF3Y80nmlmdwOvuvvl4eMNrzVaXNlk\nG9WNHtfT/M9MrR892HisdY6nyt0nh4fBfxH4MnAXofuP5APT3L3WzLYA3Zp5vQE/cfdft/F9RSJC\nu7Yknr1EaMRcAMzsg+G2czg6NPb1Ab7/QkK71ACuaWlldz9M6Ha63zCzFEJ17gmHyFnA0PCqFUB2\no5e+CNwY7m1hZgPNrE+E2iDSIgWJxIsMMytuNP0boV/KheED0KsIDf8P8N/AT8xsCcH2yr8G/JuZ\nLSd0c6GDLb3A3ZcQGun3WkL3Hyk0sxXAZwgd28Hdy4A3w6cL3+HuLxHadfZ2eN35fDRoRAKl039F\nAhLeVVXl7m5m1wDXuvulLb1OJNboGIlIcKYBd4fPtDpAFG5fLNIZ1CMREZEO0TESERHpEAWJiIh0\niIJEREQ6REEiIiIdoiAREZEOUZCIiEiH/H/Ehp6DnOLzjAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgN4QfJhea2X",
        "colab_type": "code",
        "outputId": "753390bf-0128-4b10-8a27-f8811a7b705d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.496573</td>\n",
              "      <td>4.170835</td>\n",
              "      <td>0.259859</td>\n",
              "      <td>01:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyGMsCrHe19M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('fit_head2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGLwIfo6fCeF",
        "colab_type": "code",
        "outputId": "8ac47a17-625b-420a-8c7e-21d67d1494a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.load('fit_head2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (33403 items)\n",
              "x: LMTextList\n",
              "xxbos xxunk i know this kid is like kinda ugly but he 's still cute,xxbos xxmaj yay for xxunk being out of school next week ☺ ️ # sarcasm,xxbos xxmaj yay , xxmaj friday tomorrow ! 😄 xxmaj how i love my day off to chill , appreciate nice things & generally embrace all that is good about life 😄 ❤,xxbos i 'm impressed in a way that you got to speak . xxmaj we got , xxunk to me , do n't speak to me ' so we never knew which . xxmaj same result,xxbos xxmaj it 's not so much blowing my diet as preventing the xxunk from developing freezer burn . # sarcasm\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (8352 items)\n",
              "x: LMTextList\n",
              "xxbos xxunk _ xxmaj awesome and sounds good ! xxmaj have fun doing your homework ! tweet me when you 're finished ! :) # sarcasm,xxbos i just took a shower and only shaved one leg .. xxmaj what is wrong with me lol # sarcasm,xxbos xxmaj my momma tryna get me a car for xxmaj christmas .. without a license 😭 # sarcasm,xxbos xxmaj rt if you failed the xxmaj physics test,xxbos xxmaj arguing with my mom is the best .. xxunk me tell ya\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(12224, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=12224, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f13dd1b2c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (33403 items)\n",
              "x: LMTextList\n",
              "xxbos xxunk i know this kid is like kinda ugly but he 's still cute,xxbos xxmaj yay for xxunk being out of school next week ☺ ️ # sarcasm,xxbos xxmaj yay , xxmaj friday tomorrow ! 😄 xxmaj how i love my day off to chill , appreciate nice things & generally embrace all that is good about life 😄 ❤,xxbos i 'm impressed in a way that you got to speak . xxmaj we got , xxunk to me , do n't speak to me ' so we never knew which . xxmaj same result,xxbos xxmaj it 's not so much blowing my diet as preventing the xxunk from developing freezer burn . # sarcasm\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (8352 items)\n",
              "x: LMTextList\n",
              "xxbos xxunk _ xxmaj awesome and sounds good ! xxmaj have fun doing your homework ! tweet me when you 're finished ! :) # sarcasm,xxbos i just took a shower and only shaved one leg .. xxmaj what is wrong with me lol # sarcasm,xxbos xxmaj my momma tryna get me a car for xxmaj christmas .. without a license 😭 # sarcasm,xxbos xxmaj rt if you failed the xxmaj physics test,xxbos xxmaj arguing with my mom is the best .. xxunk me tell ya\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(12224, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=12224, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f13dd1b2c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=12224, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=12224, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncdwMMl3fHS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5zxh9UnfUYj",
        "colab_type": "code",
        "outputId": "594edb92-4d2f-4988-f34d-f858d3fe6798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "learn.fit_one_cycle(6, 1e-3, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.133701</td>\n",
              "      <td>4.012432</td>\n",
              "      <td>0.279565</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.002191</td>\n",
              "      <td>3.924612</td>\n",
              "      <td>0.288983</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.825993</td>\n",
              "      <td>3.860623</td>\n",
              "      <td>0.298687</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.630345</td>\n",
              "      <td>3.839178</td>\n",
              "      <td>0.302530</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.468774</td>\n",
              "      <td>3.834478</td>\n",
              "      <td>0.304496</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.365428</td>\n",
              "      <td>3.843884</td>\n",
              "      <td>0.303938</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wKzwRw3fZci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('fine_tuned3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64RwY1Q4itsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.load('fine_tuned3');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw4Ds2o7i14i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"I enjoy\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBsyuQLMjAKC",
        "colab_type": "code",
        "outputId": "e286014c-982a-4689-f06c-c04ed7e94ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I enjoy listening to Danny Bliss on the radio . It 's a great feeling here . # not # sarcasm xxbos Cleaning your house and cleaning my room 's room is like fucking great # sarcasm xxbos\n",
            "I enjoy the smell of freshly washed clothes xxbos Dear Computer Lab , Doctors Lab , Lab Lab , Science Lab Physics , Physics Test , Physics ,\n",
            "I enjoy looking at my books for like 3 years . i 'm not about to be able to write on a paper . # sarcasm xxbos RT The Parents are So Happy We Are\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKSSb1NLjC8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('fine_tuned_enc3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leLYqW9yICv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.name = df.replace(to_replace='#sarcasm', value=\"\",regex=True, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F7cRvbtIj9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('mod_train.csv', index=False)\n",
        "#df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-RC80JLjLGJ",
        "colab_type": "code",
        "outputId": "a4b9d1e3-3d09-4ed3-99a6-8b09b04bc894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "data_clas = TextDataBunch.from_csv('', 'mod_train.csv', text_cols=2, label_cols=1, vocab=data_lm.vocab)\n",
        "data_clas.save('data_clas1.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK5vMPOGnCGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas = load_data('','data_clas1.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpbFOD0MjeQa",
        "colab_type": "code",
        "outputId": "31d34a68-7d28-4c26-8525-fb52f4e16f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data_clas.train_ds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31823"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN8H5NmKl_OG",
        "colab_type": "code",
        "outputId": "c90472d3-b25c-4a51-bc65-21b3aa0ccf33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.7)\n",
        "learn.load_encoder('fine_tuned_enc2')\n",
        "#learn.clip_grad(0.3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f1de30b5d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f1de30b5d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x3FBtXlenET",
        "colab_type": "code",
        "outputId": "3e218ef8-edc1-4e6c-d075-c10bca72d6aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.load('fifth3_final_93%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f1de30b5d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f1de30b5d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr9wSYhneymi",
        "colab_type": "code",
        "outputId": "fcfab077-e8d9-4fcf-ecf6-e8eac41f5075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "learn.export('final_model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SequentialRNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MultiBatchEncoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AWD_LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type EmbeddingDropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WeightDropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNNDropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type PoolingLinearClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm1d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHoH5463mGjB",
        "colab_type": "code",
        "outputId": "f21884bc-47a9-4e1a-aca2-28e6830380da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xZevY3hmKMO",
        "colab_type": "code",
        "outputId": "98a30d0d-5e95-428e-e373-1ccfa620773b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWCIxxhhTK5ZIjDHG1Mr/A9w7a4lwQ51PAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX8-gmWOmMoz",
        "colab_type": "code",
        "outputId": "dcc3f941-5ed7-4504-ba1b-1c395531a2ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-3, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.485765</td>\n",
              "      <td>0.399010</td>\n",
              "      <td>0.822043</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTIjyToxmUpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('first2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb3yiI-Ymgr4",
        "colab_type": "code",
        "outputId": "32571454-64f8-428b-891c-2e8f38eb12e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.load('first2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f13dd1b2c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f13dd1b2c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JwvFhTgmjyd",
        "colab_type": "code",
        "outputId": "82c633f4-bcf1-4b9f-a988-1825467e7b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.463372</td>\n",
              "      <td>0.389290</td>\n",
              "      <td>0.824934</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_p2T4W4FBq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d49a9ee7-464b-4c1a-a303-5249e3322fb1",
        "id": "-ImPtTX7FDCl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.predict(\"Can't wait to see more of your breast feeding selfies.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category 1, tensor(1), tensor([0.1752, 0.8248]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAMPgE5ampng",
        "colab_type": "code",
        "outputId": "cc250cf8-8531-41ae-80d5-b876909c90a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.save('second3')\n",
        "learn.load('second3')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f8c8d3b8c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f8c8d3b8c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60A38SvBm1wy",
        "colab_type": "code",
        "outputId": "d9677e86-cc24-491d-fbcf-b5dc76fc5aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.428216</td>\n",
              "      <td>0.373283</td>\n",
              "      <td>0.831595</td>\n",
              "      <td>01:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_GLTrPbm6g-",
        "colab_type": "code",
        "outputId": "428153f3-3b60-4ae8-f5b1-1936243a37a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.save('third2')\n",
        "learn.load('third2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f13dd1b2c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f13dd1b2c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL36uxFAnM8Z",
        "colab_type": "code",
        "outputId": "425eb752-da76-4bb2-9fa3-d5e3ac58a6ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(4, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.395034</td>\n",
              "      <td>0.362349</td>\n",
              "      <td>0.838758</td>\n",
              "      <td>01:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.378276</td>\n",
              "      <td>0.344203</td>\n",
              "      <td>0.850698</td>\n",
              "      <td>01:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.338452</td>\n",
              "      <td>0.337784</td>\n",
              "      <td>0.856102</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.314576</td>\n",
              "      <td>0.339654</td>\n",
              "      <td>0.859118</td>\n",
              "      <td>01:26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaFjsYeWnRu-",
        "colab_type": "code",
        "outputId": "88c96bb2-0e65-4c98-82b0-41a60fe5e88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.save('final5')\n",
        "learn.load('final5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f7ac7eb7ea0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f7ac7eb7ea0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.24, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8geEd41jSPj",
        "colab_type": "code",
        "outputId": "b6b16467-3438-469f-d54a-4f33c9dffe0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.328530</td>\n",
              "      <td>0.335988</td>\n",
              "      <td>0.857484</td>\n",
              "      <td>01:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.279775</td>\n",
              "      <td>0.335740</td>\n",
              "      <td>0.860249</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFVGyzSDoF4O",
        "colab_type": "code",
        "outputId": "768526b9-a928-4395-8cea-1d0221262daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#learn.save('clip5')\n",
        "learn.load('clip5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f048e037c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), functools.partial(<class 'fastai.train.GradientClipping'>, clip=0.3)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f048e037c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), functools.partial(<class 'fastai.train.GradientClipping'>, clip=0.3)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGr6jAsJoRQ6",
        "colab_type": "code",
        "outputId": "49a8da55-4297-4052-f960-fb11c28cb201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.285963</td>\n",
              "      <td>0.301495</td>\n",
              "      <td>0.876838</td>\n",
              "      <td>01:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.249727</td>\n",
              "      <td>0.305111</td>\n",
              "      <td>0.877718</td>\n",
              "      <td>01:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiT73auwowLG",
        "colab_type": "code",
        "outputId": "7311d794-e9fb-42cd-8fc8-1973c71b4e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.save('sixth5')\n",
        "learn.load('sixth5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.32000000000000006, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f048e037c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.32000000000000006, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f048e037c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.32000000000000006, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.32000000000000006, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk3JWZLWo_nS",
        "colab_type": "code",
        "outputId": "d3732102-54d2-4333-fa38-89ab04f9223a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.337157</td>\n",
              "      <td>0.307922</td>\n",
              "      <td>0.869046</td>\n",
              "      <td>01:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.324606</td>\n",
              "      <td>0.303706</td>\n",
              "      <td>0.872439</td>\n",
              "      <td>01:15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnatKGlx3DuN",
        "colab_type": "code",
        "outputId": "6b278f67-5827-4eeb-9749-bf01a84e80b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.save('ninth5')\n",
        "learn.load('ninth5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.32000000000000006, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f048e037c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos overly general classification of people is not right . i am not the same xxup xxunk,xxbos xxup xxunk 😂 😂 😂 when the xxmaj black girl w glasses said she ca n't take care of them cus she was drinking xxmaj whiskey . xxmaj lol,xxbos xxmaj the xxmaj tiger xxunk is something special,xxbos xxmaj really excited for the xxmaj gathering tonight ! xxmaj the chapel band is singing and recording their whole album . xxmaj go if you love worship !,xxbos xxmaj sat in bed xxunk on xxmaj pick n xxmaj mix - you would n't think i was going to xxmaj mexico in 4 weeks time ! # xxunk # not # xxunk xxunk\n",
              "y: CategoryList\n",
              "0,0,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj are you high enough without the xxmaj mary xxmaj jane like me ? xxmaj saying that you should n't waste your pretty face like me .,xxbos xxmaj cut your hair they say , it will grow back xxunk and faster they say # not 😒,xxbos a webmd that takes you to a page that says \" you 're going to be fine \" would be nice .,xxbos xxunk what a day and great to be with the supporters . i 'll join you for xxmaj xxunk xxmaj rovers and try and nick some cakes from the xxmaj xxunk,xxbos xxmaj hi my birthday is today , i 'm not a xxunk but can i get a shout out from you .\n",
              "y: CategoryList\n",
              "0,1,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(12224, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(12224, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.32000000000000006, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f048e037c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.32000000000000006, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(12224, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(12224, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.32000000000000006, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7bhF38L3Qyx",
        "colab_type": "code",
        "outputId": "d2f22041-be8b-4ebc-c415-982a84a38c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.310227</td>\n",
              "      <td>0.308807</td>\n",
              "      <td>0.874576</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.286405</td>\n",
              "      <td>0.304649</td>\n",
              "      <td>0.873445</td>\n",
              "      <td>01:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hInfEeDHnv73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTdHg44ioBuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.export()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQYVjXJioqdG",
        "colab_type": "code",
        "outputId": "31908be5-dc42-4fe9-8bd6-54bd7697c0f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Gotta stay up and watch the game tonight to ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I can speak to you so honestly I can't even ru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>He says he is so grateful that he can speak so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>i'm going there next Tuesday to speak to them ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I seriously live being ignored . #not</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id                                               text\n",
              "0   0  Gotta stay up and watch the game tonight to ma...\n",
              "1   1  I can speak to you so honestly I can't even ru...\n",
              "2   2  He says he is so grateful that he can speak so...\n",
              "3   3  i'm going there next Tuesday to speak to them ...\n",
              "4   4              I seriously live being ignored . #not"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZI4HRoBVBrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "label = np.zeros((1975, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nv_gYcaa-EI",
        "colab_type": "code",
        "outputId": "4b8cc8b9-00cf-4a64-c32d-4d36824b0ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_df['text']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Gotta stay up and watch the game tonight to ma...\n",
              "1       I can speak to you so honestly I can't even ru...\n",
              "2       He says he is so grateful that he can speak so...\n",
              "3       i'm going there next Tuesday to speak to them ...\n",
              "4                   I seriously live being ignored . #not\n",
              "5       everyone in my class is ill including me so de...\n",
              "6       Actions speak louder than words . But every gi...\n",
              "7       how difficult is to sing opera-in another lang...\n",
              "8       I LOVE when some of my texts get ignored . It'...\n",
              "9       Funny coffee mugs that speak the truth so you ...\n",
              "10      thanks for making me feel soo much better #ann...\n",
              "11      I love walking from Wilson all the way to dodg...\n",
              "12      I just love how teachers have this magical con...\n",
              "13      If given the opportunity to speak to every you...\n",
              "14      Another lovely day in the job site #Sarcastict...\n",
              "15                            I like working 815-7 . #not\n",
              "16      Being half spanish and not being able to speak...\n",
              "17      I feel so awkward when people start to speak t...\n",
              "18      agree ! So many entry levels sit paralyzed to ...\n",
              "19      I have personally witnessed clogging to \" Smoo...\n",
              "20      My oatmeal exploded in the microwave . What a ...\n",
              "21          I love having to tweet stuff for classes #NOT\n",
              "22      Glad my dog chewed up the $ 40 bed I bought hi...\n",
              "23      Nothing better than having to massively reorga...\n",
              "24                                      That's real great\n",
              "25      I know i'm not \" A \" and I'm not \" C \" ... bec...\n",
              "26       Here , here . Straddle the pan like a real man .\n",
              "27      Another day with my coworker in a pissy mood ....\n",
              "28                                             Slow Tings\n",
              "29            I'm so excited to hear speak today ! Thanks\n",
              "                              ...                        \n",
              "1945    Thanks so much great to speak to you . Stay in...\n",
              "1946                           My wife making my cake : )\n",
              "1947    Everything just keeps getting better and bette...\n",
              "1948    I literally had no idea what I was doing on th...\n",
              "1949    If u think u r so perfect , then don't even sp...\n",
              "1950                         It's going to be a great day\n",
              "1951                I have a lot of friends in this class\n",
              "1952    If I could learn to properly speak to attracti...\n",
              "1953    I love how honest and open she is being about ...\n",
              "1954    I literally go grocery shopping to relax . Not...\n",
              "1955                    Gotta love having 9 - 6 days #Not\n",
              "1956    Idk wat breed i . Chasing before i speak to em...\n",
              "1957               Attention seeking sluts < < < unfollow\n",
              "1958    Good thing my professor emailed the class abou...\n",
              "1959         I just love the drive back to Brookings #Not\n",
              "1960                              Jus foolin tho 2 chainz\n",
              "1961                       10/10 thanks for replying #not\n",
              "1962    I laughed out loud at Total Eclipse of the Hea...\n",
              "1963    I love how Taco Bell in nky closes way before ...\n",
              "1964    Everybody is always picking on #multinational ...\n",
              "1965    A Guy Cheated On Three Different Girls Who Fou...\n",
              "1966    I love puking because I'm in pain . It's reall...\n",
              "1967    You don't even hardly speak to me Tell me , wh...\n",
              "1968    My english teacher told me yesterday to write ...\n",
              "1969    Nothing feels quite as good as waking up 20 mi...\n",
              "1970    I didn't get a call this morning so I'm guessi...\n",
              "1971    I don't beg for friend so whether you speak to...\n",
              "1972                Greens only ones to speak up so far .\n",
              "1973    Got ta love getting up early on your two days ...\n",
              "1974    after practice selfies are always the best 😁 #...\n",
              "Name: text, Length: 1975, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ_hOXYNVpn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1975):\n",
        "  cl,l,p = learn.predict(test_df['text'][i])\n",
        "  label[i] = int(l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pdka_Po3WYD2",
        "colab": {}
      },
      "source": [
        "cl,l,p = learn.predict(\"Can't wait to see more of your breast feeding selfies.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEAljpAHVx6b",
        "colab_type": "code",
        "outputId": "0a466812-70ab-42f2-d009-778691835000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "int(l)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO-QXxTsWcdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"submission13.csv\", label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiQj9ylDcTel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds,y,losses = learn.get_preds(with_loss=True)\n",
        "interp = ClassificationInterpretation(learn, preds, y, losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDbzvqv_gvw-",
        "colab_type": "code",
        "outputId": "71ef027c-b4e0-4c66-b9ee-de65f65a1e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "interp.plot_confusion_matrix()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAEmCAYAAAC9C19sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIRT0IhIOAWNiIRT0IhIOAWNiIT7fyxjxlr+XnXiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAXN59g-g3nq",
        "colab_type": "code",
        "outputId": "f315d9e5-1db7-44e9-9e99-e79009103f4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "interp.most_confused()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1, 526), (1, 0, 482)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhOBgPVdhyMR",
        "colab_type": "code",
        "outputId": "8d74e637-ef02-4dd2-fc39-5a9bab3e8595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 1,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJtqX_T3j9Xl",
        "colab_type": "code",
        "outputId": "8ce598ab-4694-4307-e4cb-9e97e5264440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.predict(data_clas.valid_ds[10][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category 1, tensor(1), tensor([0.2406, 0.7594]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpUg5vo-lAox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "41beb219-0dd8-4c57-f36b-7430d44cdb9e",
        "id": "-WedFZPElvwo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "#learn.unfreeze()\n",
        "learn.fit_one_cycle(8, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.342021</td>\n",
              "      <td>0.256292</td>\n",
              "      <td>0.897072</td>\n",
              "      <td>01:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qro3oOqGl0WH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cd762c1b-88e0-445f-d28e-3d7f6677de9f",
        "id": "-GV7hAeFmsuU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "#learn.unfreeze()\n",
        "learn.fit_one_cycle(8, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.313914</td>\n",
              "      <td>0.251476</td>\n",
              "      <td>0.897574</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.301312</td>\n",
              "      <td>0.248801</td>\n",
              "      <td>0.900088</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.291995</td>\n",
              "      <td>0.250607</td>\n",
              "      <td>0.895689</td>\n",
              "      <td>01:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.251883</td>\n",
              "      <td>0.243462</td>\n",
              "      <td>0.901722</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.224794</td>\n",
              "      <td>0.246024</td>\n",
              "      <td>0.902476</td>\n",
              "      <td>01:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.195769</td>\n",
              "      <td>0.246239</td>\n",
              "      <td>0.906497</td>\n",
              "      <td>01:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.174855</td>\n",
              "      <td>0.249306</td>\n",
              "      <td>0.904989</td>\n",
              "      <td>01:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.182723</td>\n",
              "      <td>0.250878</td>\n",
              "      <td>0.904110</td>\n",
              "      <td>01:21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIu5thxVmwQv",
        "colab_type": "code",
        "outputId": "9f8673a0-e7d7-4fc3-9e32-bae397ad5fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.185444</td>\n",
              "      <td>0.255751</td>\n",
              "      <td>0.901847</td>\n",
              "      <td>01:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9qXmB1Jp0I8",
        "colab_type": "code",
        "outputId": "4f395200-4ae1-40c8-c1d6-ea4b0598d09c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.load('fourth_final')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos # xxmaj great \" xxunk : xxmaj thank you all ! xxmaj xxunk xxmaj xxunk has been found,xxbos xxmaj two classes on the engineering quad ... xxmaj not out of place at all ... # awkward,xxbos xxmaj plus i ca nt even go to the gym to release my frustration because i have no xxunk there . xxmaj home alone , bored and frustrated .,xxbos xxmaj why does my stupid android keyboard keep changing words at the very last minute . xxmaj never again .,xxbos xxmaj such a sad moment when you order clothes online and they do n't look nothing like they did in the picture 😢\n",
              "y: CategoryList\n",
              "0,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj here 's an allergy xxmaj xxunk ! i love xxmaj how many different things xxmaj xxunk can help !,xxbos xxmaj they should invent wifi bracelets , so you can wear them anywhere and have wifi connection .,xxbos i hate talkin when i wake up , just dnt say shit to me for an hour or two then i 'll be good lol .,xxbos xxmaj when you realize how dumb you were for a person who could careless about you,xxbos xxmaj when you see a group of girls having an argument\n",
              "y: CategoryList\n",
              "1,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9320, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9320, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe312e8f2f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos # xxmaj great \" xxunk : xxmaj thank you all ! xxmaj xxunk xxmaj xxunk has been found,xxbos xxmaj two classes on the engineering quad ... xxmaj not out of place at all ... # awkward,xxbos xxmaj plus i ca nt even go to the gym to release my frustration because i have no xxunk there . xxmaj home alone , bored and frustrated .,xxbos xxmaj why does my stupid android keyboard keep changing words at the very last minute . xxmaj never again .,xxbos xxmaj such a sad moment when you order clothes online and they do n't look nothing like they did in the picture 😢\n",
              "y: CategoryList\n",
              "0,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj here 's an allergy xxmaj xxunk ! i love xxmaj how many different things xxmaj xxunk can help !,xxbos xxmaj they should invent wifi bracelets , so you can wear them anywhere and have wifi connection .,xxbos i hate talkin when i wake up , just dnt say shit to me for an hour or two then i 'll be good lol .,xxbos xxmaj when you realize how dumb you were for a person who could careless about you,xxbos xxmaj when you see a group of girls having an argument\n",
              "y: CategoryList\n",
              "1,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9320, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9320, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe312e8f2f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(9320, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9320, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(9320, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9320, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXpBlm4Bf-3W",
        "colab_type": "code",
        "outputId": "98875bca-3990-4d52-998e-01ce55f07549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.374852</td>\n",
              "      <td>0.274146</td>\n",
              "      <td>0.889531</td>\n",
              "      <td>00:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stcaTlNKj1q0",
        "colab_type": "code",
        "outputId": "876d42e0-e8af-4a2e-f226-710dbdac8381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.save('fifth')\n",
        "learn.load('fifth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos # xxmaj great \" xxunk : xxmaj thank you all ! xxmaj xxunk xxmaj xxunk has been found,xxbos xxmaj two classes on the engineering quad ... xxmaj not out of place at all ... # awkward,xxbos xxmaj plus i ca nt even go to the gym to release my frustration because i have no xxunk there . xxmaj home alone , bored and frustrated .,xxbos xxmaj why does my stupid android keyboard keep changing words at the very last minute . xxmaj never again .,xxbos xxmaj such a sad moment when you order clothes online and they do n't look nothing like they did in the picture 😢\n",
              "y: CategoryList\n",
              "0,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj here 's an allergy xxmaj xxunk ! i love xxmaj how many different things xxmaj xxunk can help !,xxbos xxmaj they should invent wifi bracelets , so you can wear them anywhere and have wifi connection .,xxbos i hate talkin when i wake up , just dnt say shit to me for an hour or two then i 'll be good lol .,xxbos xxmaj when you realize how dumb you were for a person who could careless about you,xxbos xxmaj when you see a group of girls having an argument\n",
              "y: CategoryList\n",
              "1,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9320, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9320, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe312e8f2f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos # xxmaj great \" xxunk : xxmaj thank you all ! xxmaj xxunk xxmaj xxunk has been found,xxbos xxmaj two classes on the engineering quad ... xxmaj not out of place at all ... # awkward,xxbos xxmaj plus i ca nt even go to the gym to release my frustration because i have no xxunk there . xxmaj home alone , bored and frustrated .,xxbos xxmaj why does my stupid android keyboard keep changing words at the very last minute . xxmaj never again .,xxbos xxmaj such a sad moment when you order clothes online and they do n't look nothing like they did in the picture 😢\n",
              "y: CategoryList\n",
              "0,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj here 's an allergy xxmaj xxunk ! i love xxmaj how many different things xxmaj xxunk can help !,xxbos xxmaj they should invent wifi bracelets , so you can wear them anywhere and have wifi connection .,xxbos i hate talkin when i wake up , just dnt say shit to me for an hour or two then i 'll be good lol .,xxbos xxmaj when you realize how dumb you were for a person who could careless about you,xxbos xxmaj when you see a group of girls having an argument\n",
              "y: CategoryList\n",
              "1,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9320, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9320, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe312e8f2f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(9320, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9320, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(9320, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9320, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVx7izp0gJz5",
        "colab_type": "code",
        "outputId": "8b113921-16fa-4858-9fe3-d738c46bb472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.368227</td>\n",
              "      <td>0.277658</td>\n",
              "      <td>0.890662</td>\n",
              "      <td>00:35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSSkzGIxhFtg",
        "colab_type": "code",
        "outputId": "0544614e-41a3-4431-dcf5-2c444d803af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.save('sixth')\n",
        "learn.load('sixth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos # xxmaj great \" xxunk : xxmaj thank you all ! xxmaj xxunk xxmaj xxunk has been found,xxbos xxmaj two classes on the engineering quad ... xxmaj not out of place at all ... # awkward,xxbos xxmaj plus i ca nt even go to the gym to release my frustration because i have no xxunk there . xxmaj home alone , bored and frustrated .,xxbos xxmaj why does my stupid android keyboard keep changing words at the very last minute . xxmaj never again .,xxbos xxmaj such a sad moment when you order clothes online and they do n't look nothing like they did in the picture 😢\n",
              "y: CategoryList\n",
              "0,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj here 's an allergy xxmaj xxunk ! i love xxmaj how many different things xxmaj xxunk can help !,xxbos xxmaj they should invent wifi bracelets , so you can wear them anywhere and have wifi connection .,xxbos i hate talkin when i wake up , just dnt say shit to me for an hour or two then i 'll be good lol .,xxbos xxmaj when you realize how dumb you were for a person who could careless about you,xxbos xxmaj when you see a group of girls having an argument\n",
              "y: CategoryList\n",
              "1,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9320, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9320, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe312e8f2f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos # xxmaj great \" xxunk : xxmaj thank you all ! xxmaj xxunk xxmaj xxunk has been found,xxbos xxmaj two classes on the engineering quad ... xxmaj not out of place at all ... # awkward,xxbos xxmaj plus i ca nt even go to the gym to release my frustration because i have no xxunk there . xxmaj home alone , bored and frustrated .,xxbos xxmaj why does my stupid android keyboard keep changing words at the very last minute . xxmaj never again .,xxbos xxmaj such a sad moment when you order clothes online and they do n't look nothing like they did in the picture 😢\n",
              "y: CategoryList\n",
              "0,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj here 's an allergy xxmaj xxunk ! i love xxmaj how many different things xxmaj xxunk can help !,xxbos xxmaj they should invent wifi bracelets , so you can wear them anywhere and have wifi connection .,xxbos i hate talkin when i wake up , just dnt say shit to me for an hour or two then i 'll be good lol .,xxbos xxmaj when you realize how dumb you were for a person who could careless about you,xxbos xxmaj when you see a group of girls having an argument\n",
              "y: CategoryList\n",
              "1,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9320, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9320, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe312e8f2f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(9320, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9320, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(9320, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9320, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxrDb5qwkPq5",
        "colab_type": "code",
        "outputId": "0d72f654-acdd-4044-be1d-981991fe226d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.357653</td>\n",
              "      <td>0.271260</td>\n",
              "      <td>0.889783</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfD_xTKxkUBw",
        "colab_type": "code",
        "outputId": "433644b7-2504-4866-bf4e-a081a5037a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#learn.save('seventh')\n",
        "learn.load('seventh')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos # xxmaj great \" xxunk : xxmaj thank you all ! xxmaj xxunk xxmaj xxunk has been found,xxbos xxmaj two classes on the engineering quad ... xxmaj not out of place at all ... # awkward,xxbos xxmaj plus i ca nt even go to the gym to release my frustration because i have no xxunk there . xxmaj home alone , bored and frustrated .,xxbos xxmaj why does my stupid android keyboard keep changing words at the very last minute . xxmaj never again .,xxbos xxmaj such a sad moment when you order clothes online and they do n't look nothing like they did in the picture 😢\n",
              "y: CategoryList\n",
              "0,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj here 's an allergy xxmaj xxunk ! i love xxmaj how many different things xxmaj xxunk can help !,xxbos xxmaj they should invent wifi bracelets , so you can wear them anywhere and have wifi connection .,xxbos i hate talkin when i wake up , just dnt say shit to me for an hour or two then i 'll be good lol .,xxbos xxmaj when you realize how dumb you were for a person who could careless about you,xxbos xxmaj when you see a group of girls having an argument\n",
              "y: CategoryList\n",
              "1,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9320, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9320, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe312e8f2f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos # xxmaj great \" xxunk : xxmaj thank you all ! xxmaj xxunk xxmaj xxunk has been found,xxbos xxmaj two classes on the engineering quad ... xxmaj not out of place at all ... # awkward,xxbos xxmaj plus i ca nt even go to the gym to release my frustration because i have no xxunk there . xxmaj home alone , bored and frustrated .,xxbos xxmaj why does my stupid android keyboard keep changing words at the very last minute . xxmaj never again .,xxbos xxmaj such a sad moment when you order clothes online and they do n't look nothing like they did in the picture 😢\n",
              "y: CategoryList\n",
              "0,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj here 's an allergy xxmaj xxunk ! i love xxmaj how many different things xxmaj xxunk can help !,xxbos xxmaj they should invent wifi bracelets , so you can wear them anywhere and have wifi connection .,xxbos i hate talkin when i wake up , just dnt say shit to me for an hour or two then i 'll be good lol .,xxbos xxmaj when you realize how dumb you were for a person who could careless about you,xxbos xxmaj when you see a group of girls having an argument\n",
              "y: CategoryList\n",
              "1,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9320, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9320, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe312e8f2f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(9320, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9320, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(9320, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9320, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY0mGDTMkmeo",
        "colab_type": "code",
        "outputId": "7c2c42f0-23ac-40f8-df0d-e3b8b2029d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.load('seventh')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos # xxmaj great \" xxunk : xxmaj thank you all ! xxmaj xxunk xxmaj xxunk has been found,xxbos xxmaj two classes on the engineering quad ... xxmaj not out of place at all ... # awkward,xxbos xxmaj plus i ca nt even go to the gym to release my frustration because i have no xxunk there . xxmaj home alone , bored and frustrated .,xxbos xxmaj why does my stupid android keyboard keep changing words at the very last minute . xxmaj never again .,xxbos xxmaj such a sad moment when you order clothes online and they do n't look nothing like they did in the picture 😢\n",
              "y: CategoryList\n",
              "0,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj here 's an allergy xxmaj xxunk ! i love xxmaj how many different things xxmaj xxunk can help !,xxbos xxmaj they should invent wifi bracelets , so you can wear them anywhere and have wifi connection .,xxbos i hate talkin when i wake up , just dnt say shit to me for an hour or two then i 'll be good lol .,xxbos xxmaj when you realize how dumb you were for a person who could careless about you,xxbos xxmaj when you see a group of girls having an argument\n",
              "y: CategoryList\n",
              "1,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9320, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9320, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f2ace636c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31823 items)\n",
              "x: TextList\n",
              "xxbos # xxmaj great \" xxunk : xxmaj thank you all ! xxmaj xxunk xxmaj xxunk has been found,xxbos xxmaj two classes on the engineering quad ... xxmaj not out of place at all ... # awkward,xxbos xxmaj plus i ca nt even go to the gym to release my frustration because i have no xxunk there . xxmaj home alone , bored and frustrated .,xxbos xxmaj why does my stupid android keyboard keep changing words at the very last minute . xxmaj never again .,xxbos xxmaj such a sad moment when you order clothes online and they do n't look nothing like they did in the picture 😢\n",
              "y: CategoryList\n",
              "0,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (7957 items)\n",
              "x: TextList\n",
              "xxbos xxmaj here 's an allergy xxmaj xxunk ! i love xxmaj how many different things xxmaj xxunk can help !,xxbos xxmaj they should invent wifi bracelets , so you can wear them anywhere and have wifi connection .,xxbos i hate talkin when i wake up , just dnt say shit to me for an hour or two then i 'll be good lol .,xxbos xxmaj when you realize how dumb you were for a person who could careless about you,xxbos xxmaj when you see a group of girls having an argument\n",
              "y: CategoryList\n",
              "1,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9320, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9320, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f2ace636c80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(9320, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9320, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(9320, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9320, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIj2XgWtvrvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}